{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc6fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d48b4-68b8-4a58-a308-ce33e918dcc4",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7fc615-f9d2-435e-811e-2f14c312e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = ''\n",
    "Entrez.api_key = ''\n",
    "\n",
    "def fetch_pubmed_id(query, max_results=100):\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record[\"IdList\"] \n",
    "\n",
    "def fetch_pubmed_abstracts(id_list, batch_size=20):\n",
    "    abstracts = []\n",
    "    for start in range(0, len(id_list), batch_size):\n",
    "        batch_ids = id_list[start:start+batch_size]\n",
    "        ids = \",\".join(batch_ids)\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"abstract\", retmode=\"xml\")\n",
    "        records = Entrez.read(handle)\n",
    "        handle.close()\n",
    "\n",
    "        for article in records['PubmedArticle']:\n",
    "            article_data = article['MedlineCitation']['Article']\n",
    "            title = article_data.get('ArticleTitle', 'No Title')\n",
    "            abstract_data = article_data.get('Abstract', {}).get('AbstractText', '')\n",
    "            if isinstance(abstract_data, list):\n",
    "                abstract_text = ' '.join([str(a) for a in abstract_data])\n",
    "            elif isinstance(abstract_data, str):\n",
    "                abstract_text = abstract_data\n",
    "            else:\n",
    "                abstract_text = ''\n",
    "\n",
    "            pmid = article['MedlineCitation']['PMID']\n",
    "            mesh_terms = [mesh['DescriptorName'] for mesh in article['MedlineCitation'].get('MeshHeadingList', [])]\n",
    "\n",
    "            abstracts.append({\n",
    "                \"pmid\": str(pmid),\n",
    "                \"title\": str(title),\n",
    "                \"abstract\": str(abstract_text),\n",
    "                \"mesh_terms\": mesh_terms,\n",
    "                \"source\": f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\"\n",
    "            })\n",
    "\n",
    "        time.sleep(0.3)  # NCBI rate limits\n",
    "\n",
    "    return abstracts\n",
    "\n",
    "def save_to_json(data, output_file):\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def fetch_and_save_pubmed_abstracts(query, max_results=100):\n",
    "    for tag, query in SEARCH_QUERIES.items():\n",
    "        ids = fetch_pubmed_id(query, max_results=100)\n",
    "        print(f\"Found {len(ids)} articles.\")\n",
    "\n",
    "        abstracts = fetch_pubmed_abstracts(ids)\n",
    "        # Auto-tagging source type\n",
    "        source_type = \"Bangladesh-specific\" if \"Bangladesh\" in query else \"Global\"\n",
    "        for doc in abstracts:\n",
    "            doc[\"source_type\"] = source_type\n",
    "\n",
    "        output_file = f\"data/processed/{tag}.json\"\n",
    "        save_to_json(abstracts, output_file)\n",
    "        \n",
    "SEARCH_QUERIES = {\n",
    "    # Infectious Diseases (High Priority for Bangladesh)\n",
    "    \"dengue_bangladesh\": \"Dengue AND Bangladesh\",\n",
    "    \"dengue_global\": \"Dengue AND (Treatment OR Guidelines)\",\n",
    "    \"typhoid_bangladesh\": \"Typhoid Fever AND Bangladesh\",\n",
    "    \"typhoid_global\": \"Typhoid Fever AND (Treatment OR Management)\",\n",
    "    \"malaria_bangladesh\": \"Malaria AND Bangladesh\",\n",
    "    \"malaria_global\": \"Malaria AND (Treatment OR Prevention)\",\n",
    "    \"hepatitis_bangladesh\": \"Hepatitis AND Bangladesh\",\n",
    "    \"hepatitis_global\": \"Hepatitis AND (Treatment OR Management)\",\n",
    "    \"diarrhea_bangladesh\": \"Diarrhea AND Bangladesh\",\n",
    "    \"diarrhea_global\": \"Diarrhea AND (Treatment OR Guidelines)\",\n",
    "    \"tuberculosis_bangladesh\": \"Tuberculosis AND Bangladesh\",\n",
    "    \"tuberculosis_global\": \"Tuberculosis AND (Treatment OR WHO Guidelines)\",\n",
    "    \"cholera_bangladesh\": \"Cholera AND Bangladesh\",\n",
    "    \"cholera_global\": \"Cholera AND (Management OR Treatment)\",\n",
    "    \"leptospirosis_bangladesh\": \"Leptospirosis AND Bangladesh\",\n",
    "    \"leptospirosis_global\": \"Leptospirosis AND Treatment\",\n",
    "    \"leishmaniasis_bangladesh\": \"Leishmaniasis AND Bangladesh\",\n",
    "    \"leishmaniasis_global\": \"Leishmaniasis AND Treatment\",\n",
    "    \"influenza_bangladesh\": \"Influenza AND Bangladesh\",\n",
    "    \"influenza_global\": \"Influenza AND Treatment\",\n",
    "\n",
    "    # Non-Communicable Diseases (NCDs)\n",
    "    \"diabetes_bangladesh\": \"Diabetes AND Bangladesh\",\n",
    "    \"diabetes_global\": \"Diabetes AND (Management OR Treatment)\",\n",
    "    \"hypertension_bangladesh\": \"Hypertension AND Bangladesh\",\n",
    "    \"hypertension_global\": \"Hypertension AND Guidelines\",\n",
    "    \"cardiovascular_bangladesh\": \"Cardiovascular Diseases AND Bangladesh\",\n",
    "    \"cardiovascular_global\": \"Cardiovascular Diseases AND Treatment\",\n",
    "    \"ckd_bangladesh\": \"Chronic Kidney Disease AND Bangladesh\",\n",
    "    \"ckd_global\": \"Chronic Kidney Disease AND Management\",\n",
    "    \"cancer_bangladesh\": \"Cancer AND Bangladesh\",\n",
    "    \"cancer_global\": \"Cancer AND (Treatment OR Management)\",\n",
    "\n",
    "    # Maternal & Child Healt\n",
    "    \"maternal_health_bangladesh\": \"Maternal Health AND Bangladesh\",\n",
    "    \"maternal_health_global\": \"Maternal Health AND Guidelines\",\n",
    "    \"neonatal_care_bangladesh\": \"Neonatal Care AND Bangladesh\",\n",
    "    \"neonatal_care_global\": \"Neonatal Care AND WHO Guidelines\",\n",
    "    \"malnutrition_bangladesh\": \"Malnutrition AND Bangladesh\",\n",
    "    \"malnutrition_global\": \"Malnutrition AND Treatment\",\n",
    "    \"immunization_bangladesh\": \"Vaccination AND Bangladesh\",\n",
    "    \"immunization_global\": \"Immunization AND WHO Guidelines\",\n",
    "\n",
    "    # Public Health & Surveillance\n",
    "    \"surveillance_bangladesh\": \"Disease Surveillance AND Bangladesh\",\n",
    "    \"surveillance_global\": \"Disease Surveillance AND WHO\",\n",
    "    \"outbreak_management_bangladesh\": \"Outbreak Response AND Bangladesh\",\n",
    "    \"outbreak_management_global\": \"Outbreak Response AND Guidelines\",\n",
    "    \"health_policy_bangladesh\": \"Health Policy AND Bangladesh\",\n",
    "    \"health_policy_global\": \"Health Policy AND Guidelines\",\n",
    "\n",
    "    # Drug & Treatment Protocols\n",
    "    \"amr_bangladesh\": \"Antibiotic Resistance AND Bangladesh\",\n",
    "    \"amr_global\": \"Antimicrobial Resistance AND WHO Guidelines\",\n",
    "    \"essential_medicines_bangladesh\": \"Essential Medicines AND Bangladesh\",\n",
    "    \"essential_medicines_global\": \"Essential Medicines AND WHO Guidelines\",\n",
    "    \"drug_pricing_bangladesh\": \"Drug Pricing AND Bangladesh\",\n",
    "    \"drug_pricing_global\": \"Drug Pricing AND Policies\",\n",
    "\n",
    "    # General Bangladesh Healthcare Queries\n",
    "    \"healthcare_system_bangladesh\": \"Healthcare System AND Bangladesh\",\n",
    "    \"primary_healthcare_bangladesh\": \"Primary Healthcare AND Bangladesh\",\n",
    "    \"rural_health_services_bangladesh\": \"Rural Health Services AND Bangladesh\",\n",
    "    \"community_health_workers_bangladesh\": \"Community Health Workers AND Bangladesh\",\n",
    "\n",
    "    # General Thematic Searches\n",
    "    \"thematic_infectious_diseases_bd\": \"Infectious Diseases AND Bangladesh\",\n",
    "    \"thematic_ncd_bd\": \"Non-communicable Diseases AND Bangladesh\",\n",
    "    \"thematic_public_health_guidelines_bd\": \"Public Health Guidelines AND Bangladesh\",\n",
    "    \"thematic_disease_surveillance_reports_bd\": \"Bangladesh Disease Surveillance Reports\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec18035e-0441-4ae3-9526-5484b4084878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting text from /data/raw/9789240104907-eng.pdf: [Errno 2] No such file or directory: '/data/raw/9789240104907-eng.pdf'\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "\n",
    "path = \"/data/raw/9789240104907-eng.pdf\" # temporary path for testing\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, overlap=100):\n",
    "    chunks = []\n",
    "    if not text:\n",
    "        return chunks\n",
    "    \n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def process_pdf_to_chunks(pdf_path, chunk_size=1000, overlap=100):\n",
    "    full_text = extract_text_from_pdf(pdf_path)\n",
    "    return chunk_text(full_text, chunk_size, overlap)\n",
    "\n",
    "\n",
    "print(process_pdf_to_chunks(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550fb42e-1cbb-45a4-a66b-18a44ecddfac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Import the generic PDF processing function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_to_text\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process_pdf_to_chunks\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Define directories\u001b[39;00m\n\u001b[32m      9\u001b[39m RAW_PDF_DIR = \u001b[33m\"\u001b[39m\u001b[33mdata/raw/\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scripts'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# Import the generic PDF processing function\n",
    "from scripts.preprocessing.pdf_to_text import process_pdf_to_chunks\n",
    "\n",
    "# Define directories\n",
    "RAW_PDF_DIR = \"data/raw/\"\n",
    "PROCESSED_JSON_DIR = \"data/processed\"\n",
    "\n",
    "def main():\n",
    "\n",
    "    os.makedirs(PROCESSED_JSON_DIR, exist_ok=True)\n",
    "    \n",
    "    all_docs = []\n",
    "    for filename in os.listdir(RAW_PDF_DIR):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(RAW_PDF_DIR, filename)\n",
    "            \n",
    "            chunks = process_pdf_to_chunks(pdf_path)\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                doc_id = str(uuid.uuid4())\n",
    "                all_docs.append({\n",
    "                    \"id\": doc_id,\n",
    "                    \"title\": filename.replace(\".pdf\", \"\"),\n",
    "                    \"body\": chunk,\n",
    "                    \"source\": f\"WHO Guidelines: {filename}\",\n",
    "                    \"language\": \"en\",\n",
    "                    \"source_type\": \"Global\"\n",
    "                })\n",
    "    \n",
    "    output_path = os.path.join(PROCESSED_JSON_DIR, \"who_guidelines.json\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_docs, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Saved {len(all_docs)} chunks to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26a6a18-2696-4ab2-ab22-7d818d1bc8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected argument 'streaming' provided to ChatGoogleGenerativeAI. Did you mean: 'disable_streaming'?\n",
      "--- Executing Fetch Node ---\n",
      "--- (Fetching HTML from: https://medex.com.bd/brands/) ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found providers ['google_genai'] for model gemini-pro, using google_genai.\n",
      "If it was not intended please specify the model provider in the graph configuration\n",
      "Scraping data from https://medex.com.bd/brands/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Executing ParseNode Node ---\n",
      "--- Executing GenerateAnswer Node ---\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Error during chain execution: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during scraping: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "\n",
      "Scraping failed. Please check:\n",
      "1. Your API key is valid\n",
      "2. The URL is accessible\n",
      "3. Your internet connection\n",
      "4. Try using a specific medicine page URL instead of the general brands page\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from scrapegraphai.graphs import SmartScraperGraph\n",
    "\n",
    "# Fix for asyncio event loop issues (especially in Jupyter notebooks)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# It is a best practice to store API keys as environment variables\n",
    "GEMINI_APIKEY = \"AIzaSyA_5Z72dRKCOAmBfLnLHMNBB2P7X-uYH9w\"\n",
    "\n",
    "graph_config = {\n",
    "    \"llm\": { \n",
    "        \"model\": \"gemini-pro\",\n",
    "        \"api_key\": GEMINI_APIKEY,\n",
    "        \"temperature\": 0,\n",
    "        \"disable_streaming\": True  # Fix for streaming argument warning\n",
    "    },\n",
    "    \"verbose\": True,\n",
    "    \"headless\": True\n",
    "}\n",
    "\n",
    "# Example of a specific medicine page URL (you need to use actual medicine page URLs)\n",
    "# This is just an example - replace with actual medicine page URLs\n",
    "medex_url = \"https://medex.com.bd/brands/\"\n",
    "\n",
    "# Updated prompt to be more flexible\n",
    "user_prompt = \"\"\"\n",
    "Extract all available information about medicines from this page. \n",
    "If this is a brand listing page, extract:\n",
    "- List of all brand names\n",
    "- Associated generic names (if available)\n",
    "- Manufacturers (if available)\n",
    "\n",
    "If this is a specific medicine page, extract:\n",
    "- Brand name of the medicine\n",
    "- Generic name\n",
    "- Strength of the medicine\n",
    "- Manufacturer\n",
    "- Dosage form\n",
    "- Indications for use\n",
    "- Pharmacology\n",
    "- Dosage and administration instructions\n",
    "- Precautions or warnings\n",
    "- Side effects\n",
    "- Storage conditions\n",
    "\n",
    "Return the output as a JSON object. If information is not available, use null values.\n",
    "\"\"\"\n",
    "\n",
    "def scrape_medex_data(url, prompt):\n",
    "    \"\"\"\n",
    "    Uses Scrapegraph-ai to scrape a specific URL based on a prompt.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        scraper = SmartScraperGraph(\n",
    "            prompt=prompt,\n",
    "            source=url,\n",
    "            config=graph_config\n",
    "        )\n",
    "        \n",
    "        print(f\"Scraping data from {url}...\")\n",
    "        \n",
    "        # Alternative method to avoid asyncio issues\n",
    "        try:\n",
    "            result = scraper.run()\n",
    "        except RuntimeError as e:\n",
    "            if \"asyncio.run() cannot be called from a running event loop\" in str(e):\n",
    "                # Try using asyncio directly\n",
    "                loop = asyncio.new_event_loop()\n",
    "                asyncio.set_event_loop(loop)\n",
    "                try:\n",
    "                    result = loop.run_until_complete(scraper.arun())\n",
    "                finally:\n",
    "                    loop.close()\n",
    "            else:\n",
    "                raise e\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during scraping: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Run the scraping function\n",
    "    scraped_data = scrape_medex_data(medex_url, user_prompt)\n",
    "    \n",
    "    if scraped_data:\n",
    "        print(\"\\nScraping successful. Here is the output:\")\n",
    "        print(json.dumps(scraped_data, indent=4, ensure_ascii=False))\n",
    "        \n",
    "        # Optionally save to file\n",
    "        try:\n",
    "            with open('medex_data.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(scraped_data, f, indent=4, ensure_ascii=False)\n",
    "            print(\"\\nData saved to 'medex_data.json'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving file: {str(e)}\")\n",
    "    else:\n",
    "        print(\"\\nScraping failed. Please check:\")\n",
    "        print(\"1. Your API key is valid\")\n",
    "        print(\"2. The URL is accessible\")\n",
    "        print(\"3. Your internet connection\")\n",
    "        print(\"4. Try using a specific medicine page URL instead of the general brands page\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42e521-849f-4bad-b391-b407ec1ee144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
